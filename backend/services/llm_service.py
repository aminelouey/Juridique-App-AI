"""
LLM Service - GÃ©nÃ©ration de rÃ©ponses avec Groq (LLaMA cloud)
"""

import os
from typing import Optional
from abc import ABC, abstractmethod


class BaseLLM(ABC):
    @abstractmethod
    async def generate(self, prompt: str, context: str) -> str:
        pass


class GroqLLM(BaseLLM):
    """Groq Cloud LLM - Fast LLaMA inference"""
    
    def __init__(self, api_key: str, model: str = "llama-3.1-8b-instant"):
        self.api_key = api_key
        self.model = model
        
    async def initialize(self):
        print(f"âœ… Groq initialized with model: {self.model}")
    
    async def generate(self, prompt: str, context: str) -> str:
        import aiohttp
        
        system_prompt = """Tu es un assistant juridique algÃ©rien expert du Code pÃ©nal.
Tu dois:
- RÃ©pondre en franÃ§ais de maniÃ¨re claire et professionnelle
- Utiliser UNIQUEMENT les informations du contexte fourni
- Citer les articles de loi quand disponibles
- Mentionner les sanctions (prison et amende)
- NE JAMAIS inventer d'informations non prÃ©sentes dans le contexte
- Ajouter un avertissement que c'est une information gÃ©nÃ©rale, pas un conseil juridique

Si le contexte ne contient pas l'information demandÃ©e, dis-le clairement."""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"Contexte juridique:\n{context}\n\nQuestion: {prompt}"}
        ]
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model,
            "messages": messages,
            "temperature": 0.3,
            "max_tokens": 800
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "https://api.groq.com/openai/v1/chat/completions",
                headers=headers,
                json=payload
            ) as response:
                if response.status == 200:
                    data = await response.json()
                    return data["choices"][0]["message"]["content"]
                else:
                    error = await response.text()
                    return f"Erreur Groq ({response.status}): {error}"


class MockLLM(BaseLLM):
    """Mock LLM for testing without API keys"""
    
    async def initialize(self):
        print("âœ… Mock LLM initialized (no API needed)")
    
    async def generate(self, prompt: str, context: str) -> str:
        return f"""ðŸ“‹ **RÃ©ponse Ã  votre question:** "{prompt}"

{context}

---
âš ï¸ **Avertissement juridique:** Cette rÃ©ponse est une information juridique gÃ©nÃ©rale basÃ©e sur le Code pÃ©nal algÃ©rien et ne constitue pas un avis juridique personnalisÃ©. Pour toute situation spÃ©cifique, consultez un avocat."""


class LLMService:
    """Service principal pour la gÃ©nÃ©ration LLM - Utilise Groq Cloud"""
    
    def __init__(self):
        self.llm: Optional[BaseLLM] = None
        self.provider: str = "mock"
        
    async def initialize(self):
        """Initialize LLM - prioritÃ© Ã  Groq"""
        groq_key = os.getenv("GROQ_API_KEY")
        
        if groq_key:
            self.llm = GroqLLM(api_key=groq_key)
            self.provider = "groq"
        else:
            self.llm = MockLLM()
            self.provider = "mock"
        
        await self.llm.initialize()
        print(f"ðŸ¤– LLM Provider: {self.provider}")
        
    async def generate_response(self, question: str, context: str) -> str:
        if not self.llm:
            await self.initialize()
        return await self.llm.generate(question, context)
